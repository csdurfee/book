{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Paradoxes\n",
    "\n",
    "In machine learning and deep learning, we do a lot of tasks involving classification. Is this mushroom safe to eat? Is this person a good or bad credit risk? Is this a cat or a dog?\n",
    "\n",
    "Different machine learning algorithms have different strengths and weaknesses.\n",
    "\n",
    "It's natural to think that combining multiple models together will produce better (or at least more robust) results than the individuals. This is called an ensemble.\n",
    "\n",
    "Imagine a binary classification problem. we have a bunch of photos. 0=Dog, 1=Cat. We build 3 classification systems. Each one has an accuracy of around 70%. We will create these fake classifiers by taking the true results and flipping 30% of the bits in them.\n",
    "\n",
    "Then we'll create an ensemble of the three by taking the majority pick (at least 2 of 3 agree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "rng = np.random.default_rng(2718)\n",
    "\n",
    "def create_ground_truth(num_bits):\n",
    "    return [rng.random() > .5 for x in range(num_bits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False, True, True, True, True, True, False]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS = 100000\n",
    "\n",
    "ground_truth = create_ground_truth(NUM_BITS)\n",
    "\n",
    "ground_truth[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_systems(ground_truth, num_systems, flip_ratio=.4):\n",
    "    \"\"\"\n",
    "    flips a certain number of bits, according to `flip_ratio`\n",
    "    \"\"\"\n",
    "    systems = [ground_truth.copy() for x in range(3)]\n",
    "\n",
    "    for system in systems:\n",
    "        for count, bit in enumerate(system):\n",
    "            if rng.random() < flip_ratio:\n",
    "                system[count] = not(bit)\n",
    "    return systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each of the systems agree with the ground truth about 60% of the time, as would be expected from randomly flipping 40% of the bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5994074785811514\n",
      "0.6017316017316018\n",
      "0.5993384121892542\n"
     ]
    }
   ],
   "source": [
    "systems = create_systems(ground_truth, 3)\n",
    "\n",
    "print(f1_score(ground_truth, systems[0]))\n",
    "print(f1_score(ground_truth, systems[1]))\n",
    "print(f1_score(ground_truth, systems[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.Series(systems[0]) == pd.Series(systems[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_consensus(systems):\n",
    "    \"\"\"\n",
    "    do a consensus pick. round each one and then pick the most popular answer\n",
    "\n",
    "    this function is really, really slow, because the 'mode' function doesn't accept booleans.\n",
    "    \"\"\"\n",
    "    consensus = []\n",
    "    for x in range(len(systems[0])):\n",
    "        system_picks = [int(s[x]) for s in systems]\n",
    "        ### there are only two possible choices (0 or 1) so there will always be a majority\n",
    "        ### winner with an odd number of systems.\n",
    "\n",
    "        chosen_bit = mode(system_picks).mode\n",
    "        consensus.append(bool(chosen_bit))\n",
    "    return consensus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus = do_consensus(systems)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65     49965\n",
      "           1       0.65      0.64      0.65     50035\n",
      "\n",
      "    accuracy                           0.65    100000\n",
      "   macro avg       0.65      0.65      0.65    100000\n",
      "weighted avg       0.65      0.65      0.65    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ground_truth, consensus, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! the ensemble works! the consensus f1 score (0.65) is higher than the individual ones (.58, .59, .55).\n",
    "\n",
    "Adding more systems doesn't increase the accuracy, though. We can't erase the randomness entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65     49965\n",
      "           1       0.65      0.65      0.65     50035\n",
      "\n",
      "    accuracy                           0.65    100000\n",
      "   macro avg       0.65      0.65      0.65    100000\n",
      "weighted avg       0.65      0.65      0.65    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "systems2 = create_systems(ground_truth, 15)\n",
    "consensus2 = do_consensus(systems2)\n",
    "print(classification_report(ground_truth, consensus2, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't get rid of the noise by adding a huge number of systems, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65     49965\n",
      "           1       0.65      0.64      0.65     50035\n",
      "\n",
      "    accuracy                           0.65    100000\n",
      "   macro avg       0.65      0.65      0.65    100000\n",
      "weighted avg       0.65      0.65      0.65    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "systems3 = create_systems(ground_truth, 151)\n",
    "consensus3 = do_consensus(systems3)\n",
    "print(classification_report(ground_truth, consensus3, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we take a different approach -- imagine each system outputs a float that rounds to the right value 60% of the time. Instead of rounding each one and going with the majority opinion, we add together the floats and then round the result.\n",
    "\n",
    "To model this, I will take the ground truth, flip 40% of the bits, then add some noise to each one, but not enough to change what it will round to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_ground(ground_truth):\n",
    "    \"\"\"\n",
    "    this takes the boolean ground truth and adds some random noise to the values\n",
    "    so they are a float between 0 and 1 rather than a boolean. These fuzzy values \n",
    "    should round to the original booleans.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for bit in ground_truth:\n",
    "        if bit:\n",
    "            # pick a number between .5 and 1\n",
    "            fuzzy = (rng.random() + 1) / 2\n",
    "        else:\n",
    "            # pick a number between 0 and .5\n",
    "            fuzzy = rng.random() / 2\n",
    "        out.append(fuzzy)\n",
    "    return out\n",
    "\n",
    "def create_fuzzy_systems(ground_truth, num_systems=5, flip_ratio=.4):\n",
    "    \"\"\"\n",
    "    generate systems, as before, then add some noise to each bit.\n",
    "    \"\"\"\n",
    "    regular_systems = create_systems(ground_truth, num_systems, flip_ratio)\n",
    "\n",
    "    fuzzy_systems = []\n",
    "    for system in regular_systems:\n",
    "        fuzzed = fuzzy_ground(system)\n",
    "        fuzzy_systems.append(pd.Series(fuzzed))\n",
    "\n",
    "    return fuzzy_systems\n",
    "\n",
    "def fuzzy_ensemble(systems):\n",
    "    rounded = np.round(np.mean(systems, axis=0))\n",
    "    return rounded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To hammer the point here, I'm going to create an ensemble of 999 of these fuzzy systems. Looking at one of them, we can see that it still gives results that are correct 60% of the time. So, no funny business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60     49965\n",
      "           1       0.60      0.60      0.60     50035\n",
      "\n",
      "    accuracy                           0.60    100000\n",
      "   macro avg       0.60      0.60      0.60    100000\n",
      "weighted avg       0.60      0.60      0.60    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fuzzy_sys = create_fuzzy_systems(ground_truth, 999, .4)\n",
    "\n",
    "sample_fuzz = round(fuzzy_sys[0])\n",
    "\n",
    "print(classification_report(ground_truth, sample_fuzz, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble does help, but only a little. Even with 999 systems in the ensemble, the f1 score only goes from 60% to 62%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63     49965\n",
      "           1       0.63      0.62      0.62     50035\n",
      "\n",
      "    accuracy                           0.62    100000\n",
      "   macro avg       0.62      0.62      0.62    100000\n",
      "weighted avg       0.62      0.62      0.62    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fuzz_ensemble_results = fuzzy_ensemble(fuzzy_sys)\n",
    "\n",
    "print(classification_report(ground_truth, fuzz_ensemble_results, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
